{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.layers import BatchNormalization, Dense, Embedding, Input, Concatenate, Flatten, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow import one_hot\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>company</th>\n",
       "      <th>is_local</th>\n",
       "      <th>type</th>\n",
       "      <th>fin_1</th>\n",
       "      <th>fin_2</th>\n",
       "      <th>fin_3</th>\n",
       "      <th>fin_4</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>40.10891</td>\n",
       "      <td>-83.09286</td>\n",
       "      <td>8336</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-135060.089443</td>\n",
       "      <td>86013.396489</td>\n",
       "      <td>1206.094242</td>\n",
       "      <td>52287.082257</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>39.86542</td>\n",
       "      <td>-84.06280</td>\n",
       "      <td>18403</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1766.845055</td>\n",
       "      <td>14985.640180</td>\n",
       "      <td>477.494992</td>\n",
       "      <td>168836.215743</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>39.10266</td>\n",
       "      <td>-84.52468</td>\n",
       "      <td>14022</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-177302.873693</td>\n",
       "      <td>44881.958005</td>\n",
       "      <td>1463.339889</td>\n",
       "      <td>130388.243325</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>39.10148</td>\n",
       "      <td>-84.52341</td>\n",
       "      <td>11051</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>209049.997460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>95.340075</td>\n",
       "      <td>103267.727546</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>41.06213</td>\n",
       "      <td>-81.53784</td>\n",
       "      <td>3243</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8669.269507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>399.421926</td>\n",
       "      <td>177532.206618</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  latitude  longitude  company  is_local  type          fin_1  \\\n",
       "0           0  40.10891  -83.09286     8336         0     3 -135060.089443   \n",
       "1           1  39.86542  -84.06280    18403         1     0   -1766.845055   \n",
       "2           2  39.10266  -84.52468    14022         0     3 -177302.873693   \n",
       "3           3  39.10148  -84.52341    11051         0     0  209049.997460   \n",
       "4           4  41.06213  -81.53784     3243         0     3    8669.269507   \n",
       "\n",
       "          fin_2        fin_3          fin_4  target  \n",
       "0  86013.396489  1206.094242   52287.082257       0  \n",
       "1  14985.640180   477.494992  168836.215743       1  \n",
       "2  44881.958005  1463.339889  130388.243325       0  \n",
       "3      0.000000    95.340075  103267.727546       1  \n",
       "4      0.000000   399.421926  177532.206618       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_df(df):\n",
    "    df = df.drop(columns=df.columns[0])\n",
    "    mask = df['company'].value_counts()\n",
    "    df['company'] = np.where(df['company'].isin(mask.index[mask>=10]), df.company, -1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 42.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df = transform_df(train_df)\n",
    "test_df = transform_df(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=300, random_state=42)\n",
    "train_df['geo'] = km.fit_predict(train_df[['latitude', 'longitude']])\n",
    "test_df['geo'] = km.predict(test_df[['latitude', 'longitude']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(train_df.company)\n",
    "train_df['company'] = le.transform(train_df.company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['company'] = np.where(test_df['company'].isin(train_df['company'].unique()), test_df['company'], -1)\n",
    "test_df['company'] = le.transform(test_df.company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train_df.drop('target', axis=1), \n",
    "                                                      train_df.target, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = ['fin_1', 'fin_2', 'fin_3', 'fin_4', 'is_local']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(numeric_data, company_data, type_data, geo_data, num_company):\n",
    "    numeric_input = Input(shape=(5,), dtype=tf.float32, name=\"numeric_data\")\n",
    "    numeric = Dense(32, activation='relu')(numeric_input)\n",
    "    numeric = BatchNormalization()(numeric)\n",
    "    numeric = Dense(32, activation='relu')(numeric)\n",
    "    numeric = BatchNormalization()(numeric)\n",
    "    numeric = Reshape((1, 32))(numeric)\n",
    "\n",
    "    \n",
    "    company_input = Input(shape=(1,), dtype=tf.float32, name=\"company_data\")\n",
    "    company = Embedding(num_company + 1, 64)(company_input)\n",
    "    company = Dense(32, activation='relu')(company)\n",
    "    # company = Reshape((-1, 32))(company)\n",
    "\n",
    "    type_l_input = Input(shape=(1,), dtype=tf.float32, name=\"type_data\")\n",
    "    type_l = Embedding(6, 8)(type_l_input)\n",
    "    # type_l = Reshape((-1, 8))(type_l)\n",
    "\n",
    "    geo_input = Input(shape=(1,), dtype=tf.float32, name=\"geo_data\")\n",
    "    geo = Embedding(300, 32)(geo_input)\n",
    "    geo = Dense(32, activation='relu')(geo)\n",
    "    # geo = Reshape((-1, 32))(geo)\n",
    "\n",
    "    \n",
    "    out = Concatenate()([numeric, company, type_l, geo])\n",
    "    out = Dense(64, activation='relu')(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Dense(64, activation='relu')(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Dense(1, activation=\"sigmoid\")(out)\n",
    "    \n",
    "    model = Model(inputs=[numeric_input, company_input, type_l_input, geo_input], outputs=out)\n",
    "    model.compile(Adam(learning_rate=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_model(train_df[numeric_cols].values, train_df.company.values, \n",
    "                    train_df.type.values, train_df.geo.values, train_df.company.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "numeric_data (InputLayer)       [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           192         numeric_data[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32)           128         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           1056        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "company_data (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "geo_data (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32)           128         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 64)        94976       company_data[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "type_data (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 32)        9600        geo_data[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1, 32)        0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1, 32)        2080        embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 8)         48          type_data[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1, 32)        1056        embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1, 104)       0           reshape[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "                                                                 embedding_1[0][0]                \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1, 64)        6720        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1, 64)        256         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1, 64)        4160        batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1, 64)        256         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1, 1)         65          batch_normalization_3[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 120,721\n",
      "Trainable params: 120,337\n",
      "Non-trainable params: 384\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "train_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices(({\"numeric_data\": X_train[numeric_cols].values, \n",
    "                          \"company_data\": X_train.company.values, \n",
    "                          \"type_data\": X_train.type.values, \n",
    "                          \"geo_data\": X_train.geo.values}, y_train))\n",
    "    .shuffle(2048)\n",
    "    .batch(BATCH_SIZE)\n",
    ")\n",
    "\n",
    "valid_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices(({\"numeric_data\": X_valid[numeric_cols].values, \n",
    "                          \"company_data\": X_valid.company.values, \n",
    "                          \"type_data\": X_valid.type.values, \n",
    "                          \"geo_data\": X_valid.geo.values}, y_valid))\n",
    "    .batch(BATCH_SIZE)\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='.',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1125/1125 [==============================] - 5s 3ms/step - loss: 0.6241 - accuracy: 0.6703 - val_loss: 0.5046 - val_accuracy: 0.7481\n",
      "Epoch 2/10\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.4972 - accuracy: 0.7550 - val_loss: 0.4697 - val_accuracy: 0.7683\n",
      "Epoch 3/10\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4770 - accuracy: 0.7604 - val_loss: 0.4567 - val_accuracy: 0.7710\n",
      "Epoch 4/10\n",
      "1125/1125 [==============================] - 4s 3ms/step - loss: 0.4665 - accuracy: 0.7651 - val_loss: 0.4487 - val_accuracy: 0.7721\n",
      "Epoch 5/10\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4598 - accuracy: 0.7649 - val_loss: 0.4438 - val_accuracy: 0.7735\n",
      "Epoch 6/10\n",
      "1125/1125 [==============================] - 4s 3ms/step - loss: 0.4554 - accuracy: 0.7655 - val_loss: 0.4400 - val_accuracy: 0.7740\n",
      "Epoch 7/10\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4515 - accuracy: 0.7674 - val_loss: 0.4374 - val_accuracy: 0.7748\n",
      "Epoch 8/10\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4501 - accuracy: 0.7682 - val_loss: 0.4355 - val_accuracy: 0.7746\n",
      "Epoch 9/10\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4475 - accuracy: 0.7687 - val_loss: 0.4344 - val_accuracy: 0.7752\n",
      "Epoch 10/10\n",
      "1125/1125 [==============================] - 4s 3ms/step - loss: 0.4462 - accuracy: 0.7695 - val_loss: 0.4334 - val_accuracy: 0.7757\n",
      "Wall time: 37.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_steps = X_train.shape[0] // BATCH_SIZE\n",
    "train_history = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=n_steps,\n",
    "    validation_data=valid_dataset,\n",
    "    epochs=10, \n",
    "    callbacks=[model_checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "test_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices(({\"numeric_data\": test_df[numeric_cols].values, \n",
    "                          \"company_data\": test_df.company.values, \n",
    "                          \"type_data\": test_df.type.values, \n",
    "                          \"geo_data\": test_df.geo.values}))\n",
    "    .batch(BATCH_SIZE)\n",
    ")\n",
    "predictions = model.predict(test_dataset, verbose=1).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40665"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_df.target.values, predictions.reshape(-1))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f3ad2d559e150037d3aea5fed8327b1752ca5eee44973edca35cda80d58ba91"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
