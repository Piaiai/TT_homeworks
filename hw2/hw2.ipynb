{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.layers import BatchNormalization, Dense, Embedding, Input, Concatenate, Flatten, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow import one_hot\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>company</th>\n",
       "      <th>is_local</th>\n",
       "      <th>type</th>\n",
       "      <th>fin_1</th>\n",
       "      <th>fin_2</th>\n",
       "      <th>fin_3</th>\n",
       "      <th>fin_4</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>40.10891</td>\n",
       "      <td>-83.09286</td>\n",
       "      <td>8336</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-135060.089443</td>\n",
       "      <td>86013.396489</td>\n",
       "      <td>1206.094242</td>\n",
       "      <td>52287.082257</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>39.86542</td>\n",
       "      <td>-84.06280</td>\n",
       "      <td>18403</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1766.845055</td>\n",
       "      <td>14985.640180</td>\n",
       "      <td>477.494992</td>\n",
       "      <td>168836.215743</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>39.10266</td>\n",
       "      <td>-84.52468</td>\n",
       "      <td>14022</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-177302.873693</td>\n",
       "      <td>44881.958005</td>\n",
       "      <td>1463.339889</td>\n",
       "      <td>130388.243325</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>39.10148</td>\n",
       "      <td>-84.52341</td>\n",
       "      <td>11051</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>209049.997460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>95.340075</td>\n",
       "      <td>103267.727546</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>41.06213</td>\n",
       "      <td>-81.53784</td>\n",
       "      <td>3243</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8669.269507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>399.421926</td>\n",
       "      <td>177532.206618</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  latitude  longitude  company  is_local  type          fin_1  \\\n",
       "0           0  40.10891  -83.09286     8336         0     3 -135060.089443   \n",
       "1           1  39.86542  -84.06280    18403         1     0   -1766.845055   \n",
       "2           2  39.10266  -84.52468    14022         0     3 -177302.873693   \n",
       "3           3  39.10148  -84.52341    11051         0     0  209049.997460   \n",
       "4           4  41.06213  -81.53784     3243         0     3    8669.269507   \n",
       "\n",
       "          fin_2        fin_3          fin_4  target  \n",
       "0  86013.396489  1206.094242   52287.082257       0  \n",
       "1  14985.640180   477.494992  168836.215743       1  \n",
       "2  44881.958005  1463.339889  130388.243325       0  \n",
       "3      0.000000    95.340075  103267.727546       1  \n",
       "4      0.000000   399.421926  177532.206618       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_df(df):\n",
    "    df = df.drop(columns=df.columns[0])\n",
    "    mask = df['company'].value_counts()\n",
    "    df['company'] = np.where(df['company'].isin(mask.index[mask>=10]), df.company, -1)\n",
    "    df['geo'] = KMeans(n_clusters=300, random_state=42).fit_predict(df[['latitude', 'longitude']])\n",
    "    df = df.drop(columns=['latitude', 'longitude'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df = transform_df(train_df)\n",
    "test_df = transform_df(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(train_df.company)\n",
    "train_df['company'] = le.transform(train_df.company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['company'] = np.where(test_df['company'].isin(train_df['company'].unique()), test_df['company'], -1)\n",
    "test_df['company'] = le.transform(test_df.company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1483"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.company.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train_df.drop('target', axis=1), \n",
    "                                                      train_df.target, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = ['fin_1', 'fin_2', 'fin_3', 'fin_4', 'is_local']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(numeric_data, company_data, type_data, geo_data, num_company):\n",
    "    numeric_input = Input(shape=(5,), dtype=tf.float32, name=\"numeric_data\")\n",
    "    numeric = Dense(32, activation='relu')(numeric_input)\n",
    "    numeric = BatchNormalization()(numeric)\n",
    "    numeric = Dense(32, activation='relu')(numeric)\n",
    "    numeric = BatchNormalization()(numeric)\n",
    "    numeric = Reshape((1, 32))(numeric)\n",
    "\n",
    "    \n",
    "    company_input = Input(shape=(1,), dtype=tf.float32, name=\"company_data\")\n",
    "    company = Embedding(num_company + 1, 64)(company_input)\n",
    "    company = Dense(32, activation='relu')(company)\n",
    "    # company = Reshape((-1, 32))(company)\n",
    "\n",
    "    type_l_input = Input(shape=(1,), dtype=tf.float32, name=\"type_data\")\n",
    "    type_l = Embedding(5, 8)(type_l_input)\n",
    "    # type_l = Reshape((-1, 8))(type_l)\n",
    "\n",
    "    geo_input = Input(shape=(1,), dtype=tf.float32, name=\"geo_data\")\n",
    "    geo = Embedding(300, 32)(geo_input)\n",
    "    geo = Dense(32, activation='relu')(geo)\n",
    "    # geo = Reshape((-1, 32))(geo)\n",
    "\n",
    "    \n",
    "    out = Concatenate()([numeric, company, type_l, geo])\n",
    "    out = Dense(64, activation='relu')(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Dense(64, activation='relu')(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Dense(1, activation=\"sigmoid\")(out)\n",
    "    \n",
    "    model = Model(inputs=[numeric_input, company_input, type_l_input, geo_input], outputs=out)\n",
    "    model.compile(Adam(learning_rate=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_model(train_df[numeric_cols].values, train_df.company.values, \n",
    "                    train_df.type.values, train_df.geo.values, train_df.company.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "train_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices(({\"numeric_data\": X_train[numeric_cols].values, \"company_data\": X_train.company.values, \n",
    "                          \"type_data\": X_train.type.values, \"geo_data\": X_train.geo.values}, y_train))\n",
    "    .shuffle(2048)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "valid_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices(({\"numeric_data\": X_valid[numeric_cols].values, \"company_data\": X_valid.company.values, \n",
    "                          \"type_data\": X_valid.type.values, \"geo_data\": X_valid.geo.values}, y_valid))\n",
    "    .batch(BATCH_SIZE)\n",
    "    .cache()\n",
    "    .prefetch(AUTO)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='.',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_steps = X_train.shape[0] // BATCH_SIZE\n",
    "train_history = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=n_steps,\n",
    "    validation_data=valid_dataset,\n",
    "    epochs=10, \n",
    "    callbacks=[model_checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "test_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices(({\"numeric_data\": test_df[numeric_cols].values, \"company_data\": test_df.company.values, \n",
    "                          \"type_data\": test_df.type.values, \"geo_data\": test_df.geo.values}, test_df.target))\n",
    "    .batch(BATCH_SIZE)\n",
    "    .cache()\n",
    "    #.prefetch(AUTO)\n",
    ")\n",
    "predictions = model.predict(test_dataset, verbose=1).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40665"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predictions, test_df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "39995    0\n",
       "39996    0\n",
       "39997    0\n",
       "39998    0\n",
       "39999    4\n",
       "Name: company, Length: 40000, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.company"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f3ad2d559e150037d3aea5fed8327b1752ca5eee44973edca35cda80d58ba91"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
